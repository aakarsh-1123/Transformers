{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "63SP5_sxhWtW"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NCQ_DrbAhZqB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1126fcde-8ff9-43b2-b49d-dedf9f91eff0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'whiteboard' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Anweshbyte/whiteboard.git\n",
        "text = open(\"/content/whiteboard/nbviewer/notebooks/data/harrypotter/Book 1 - The Philosopher's Stone.txt\", 'r').read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fpfIUD-xhgu2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "300f4da6-c5cc-43f9-c8a1-4fa266b26fef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "474379\n"
          ]
        }
      ],
      "source": [
        "sequence_length = 50\n",
        "sequences = []\n",
        "next_chars = []\n",
        "for i in range(len(text) - sequence_length):\n",
        "    sequences.append(text[i:i+sequence_length])\n",
        "    next_chars.append(text[i+sequence_length])\n",
        "print(len(sequences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BI4W1blLhg0i",
        "outputId": "42bc64d7-2e22-44dc-8f0f-31104b1807d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "84\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-e1064be221f5>:5: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  x = np.zeros((len(sequences), sequence_length, num_chars), dtype=np.bool)\n",
            "<ipython-input-4-e1064be221f5>:6: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y = np.zeros((len(sequences), num_chars), dtype=np.bool)\n"
          ]
        }
      ],
      "source": [
        "chars = sorted(set(text))\n",
        "char_indices = {char: index for index, char in enumerate(chars)}\n",
        "num_chars = len(chars)\n",
        "print(num_chars)\n",
        "x = np.zeros((len(sequences), sequence_length, num_chars), dtype=np.bool)\n",
        "y = np.zeros((len(sequences), num_chars), dtype=np.bool)\n",
        "\n",
        "\n",
        "for i, sequence in enumerate(sequences):\n",
        "    for t, char in enumerate(sequence):\n",
        "     x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2cK7L9eMhlLk"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128,input_shape=(sequence_length, num_chars)))\n",
        "model.add(Dense(num_chars, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nUoUASDKhof5"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcauZSpShpB2",
        "outputId": "96a62ac9-20cf-4500-b89f-33c46db1bd61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "7413/7413 [==============================] - 41s 6ms/step - loss: 1.2634\n",
            "Epoch 2/50\n",
            "7413/7413 [==============================] - 40s 5ms/step - loss: 1.2483\n",
            "Epoch 3/50\n",
            "7413/7413 [==============================] - 39s 5ms/step - loss: 1.2348\n",
            "Epoch 4/50\n",
            "7413/7413 [==============================] - 40s 5ms/step - loss: 1.2225\n",
            "Epoch 5/50\n",
            "7413/7413 [==============================] - 40s 5ms/step - loss: 1.2118\n",
            "Epoch 6/50\n",
            "7413/7413 [==============================] - 41s 6ms/step - loss: 1.2023\n",
            "Epoch 7/50\n",
            "7413/7413 [==============================] - 39s 5ms/step - loss: 1.1933\n",
            "Epoch 8/50\n",
            "7413/7413 [==============================] - 40s 5ms/step - loss: 1.1851\n",
            "Epoch 9/50\n",
            "7413/7413 [==============================] - 39s 5ms/step - loss: 1.1775\n",
            "Epoch 10/50\n",
            "7413/7413 [==============================] - 39s 5ms/step - loss: 1.1707\n",
            "Epoch 11/50\n",
            "7413/7413 [==============================] - 39s 5ms/step - loss: 1.1637\n",
            "Epoch 12/50\n",
            "7413/7413 [==============================] - 40s 5ms/step - loss: 1.1577\n",
            "Epoch 13/50\n",
            "7413/7413 [==============================] - 39s 5ms/step - loss: 1.1521\n",
            "Epoch 14/50\n",
            "7413/7413 [==============================] - 39s 5ms/step - loss: 1.1462\n",
            "Epoch 15/50\n",
            "7413/7413 [==============================] - 39s 5ms/step - loss: 1.1413\n",
            "Epoch 16/50\n",
            "7413/7413 [==============================] - 40s 5ms/step - loss: 1.1368\n",
            "Epoch 17/50\n",
            "7413/7413 [==============================] - 41s 5ms/step - loss: 1.1324\n",
            "Epoch 18/50\n",
            "7413/7413 [==============================] - 40s 5ms/step - loss: 1.1283\n",
            "Epoch 19/50\n",
            "7413/7413 [==============================] - 40s 5ms/step - loss: 1.1242\n",
            "Epoch 20/50\n",
            "7413/7413 [==============================] - 39s 5ms/step - loss: 1.1207\n",
            "Epoch 21/50\n",
            "7413/7413 [==============================] - 40s 5ms/step - loss: 1.1176\n",
            "Epoch 22/50\n",
            "7413/7413 [==============================] - 40s 5ms/step - loss: 1.1140\n",
            "Epoch 23/50\n",
            "7413/7413 [==============================] - 40s 5ms/step - loss: 1.1100\n",
            "Epoch 24/50\n",
            "7413/7413 [==============================] - 39s 5ms/step - loss: 1.1078\n",
            "Epoch 25/50\n",
            "7413/7413 [==============================] - 39s 5ms/step - loss: 1.1046\n",
            "Epoch 26/50\n",
            "7413/7413 [==============================] - 39s 5ms/step - loss: 1.1026\n",
            "Epoch 27/50\n",
            "7413/7413 [==============================] - 39s 5ms/step - loss: 1.0998\n",
            "Epoch 28/50\n",
            "7413/7413 [==============================] - 39s 5ms/step - loss: 1.0978\n",
            "Epoch 29/50\n",
            "7413/7413 [==============================] - 40s 5ms/step - loss: 1.0952\n",
            "Epoch 30/50\n",
            "7413/7413 [==============================] - 43s 6ms/step - loss: 1.0935\n",
            "Epoch 31/50\n",
            "7413/7413 [==============================] - 39s 5ms/step - loss: 1.0911\n",
            "Epoch 32/50\n",
            "7413/7413 [==============================] - 40s 5ms/step - loss: 1.0894\n",
            "Epoch 33/50\n",
            "7413/7413 [==============================] - 39s 5ms/step - loss: 1.0879\n",
            "Epoch 34/50\n",
            "7413/7413 [==============================] - 40s 5ms/step - loss: 1.0859\n",
            "Epoch 35/50\n",
            "7413/7413 [==============================] - 39s 5ms/step - loss: 1.0840\n",
            "Epoch 36/50\n",
            "7413/7413 [==============================] - 39s 5ms/step - loss: 1.0833\n",
            "Epoch 37/50\n",
            "7413/7413 [==============================] - 39s 5ms/step - loss: 1.0820\n",
            "Epoch 38/50\n",
            "7413/7413 [==============================] - 39s 5ms/step - loss: 1.0804\n",
            "Epoch 39/50\n",
            "7413/7413 [==============================] - 40s 5ms/step - loss: 1.0810\n",
            "Epoch 40/50\n",
            "7413/7413 [==============================] - 39s 5ms/step - loss: 1.0779\n",
            "Epoch 41/50\n",
            "7413/7413 [==============================] - 40s 5ms/step - loss: 1.0767\n",
            "Epoch 42/50\n",
            "7413/7413 [==============================] - 39s 5ms/step - loss: 1.0754\n",
            "Epoch 43/50\n",
            "7413/7413 [==============================] - 39s 5ms/step - loss: 1.0749\n",
            "Epoch 44/50\n",
            "7413/7413 [==============================] - 39s 5ms/step - loss: 1.0738\n",
            "Epoch 45/50\n",
            "7413/7413 [==============================] - 40s 5ms/step - loss: 1.0743\n",
            "Epoch 46/50\n",
            "7413/7413 [==============================] - 40s 5ms/step - loss: 1.0743\n",
            "Epoch 47/50\n",
            "7413/7413 [==============================] - 39s 5ms/step - loss: 1.0723\n",
            "Epoch 48/50\n",
            "7413/7413 [==============================] - 39s 5ms/step - loss: 1.0701\n",
            "Epoch 49/50\n",
            "7413/7413 [==============================] - 40s 5ms/step - loss: 1.0690\n",
            "Epoch 50/50\n",
            "7413/7413 [==============================] - 40s 5ms/step - loss: 1.0673\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x78362bf79870>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "model.fit(x,y,epochs=50,batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bTcdPNEnhrI3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c4912eae-f2c0-415c-9693-71d0c55308ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' their riders off. Harry \\ntried to turn back towar'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "start_index = random.randint(0, len(text) - sequence_length - 1)\n",
        "seed_sequence = text[start_index:start_index + sequence_length]\n",
        "seed_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_JfapiChtdP",
        "outputId": "d2125008-662d-436b-bb6d-2f4d1bc17586"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " their riders off. Harry \n",
            "tried to turn back toward Harry had leave pushed until \n",
            "me — that. \n",
            "\n",
            "“DURSLEYT INOW ANDONT RED!” Hagrid, “That could sey \n",
            "one on onver — about.” \n",
            "\n",
            "Page | 100 Harry Potter and the Philosopher and Ron, \n",
            "“where would you get it\n"
          ]
        }
      ],
      "source": [
        "generated_text = seed_sequence\n",
        "for _ in range(200):\n",
        "    x_pred = np.zeros((1, sequence_length, num_chars))\n",
        "    for t, char in enumerate(seed_sequence):\n",
        "        x_pred[0, t, char_indices[char]] = 1\n",
        "    predicted_probs = model.predict(x_pred, verbose=0)[0]\n",
        "    next_char_index = np.random.choice(range(num_chars), p=predicted_probs)\n",
        "    next_char= chars[next_char_index]\n",
        "    generated_text += next_char\n",
        "    seed_sequence = seed_sequence[1:] + next_char\n",
        "\n",
        "print(generated_text)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}